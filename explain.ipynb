{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70c4f8fd",
   "metadata": {},
   "source": [
    "# ExMed-BERT Data Preparation for Pretraining\n",
    "\n",
    "This notebook provides a detailed walkthrough of how patient data is prepared for pretraining a BERT-style model using the ExMed-BERT framework. It is designed for users who are new to the codebase and want to understand the data pipeline, encoding strategies, and the rationale behind each step.\n",
    "\n",
    "We will cover:\n",
    "- The purpose and structure of the main classes involved (e.g., `CodeDict`, `AgeDict`, `Patient`, `PatientDataset`)\n",
    "- How medical codes and patient attributes are encoded\n",
    "- How patient data is processed and masked for model input\n",
    "- How a dataset is constructed and saved for pretraining\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497b57a7",
   "metadata": {},
   "source": [
    "### Environment Setup Instructions\n",
    "\n",
    "1. **Create the Conda environment from the `environment.yaml` file:**\n",
    "\n",
    "    ```bash\n",
    "    conda env create -f environment.yaml\n",
    "    ```\n",
    "\n",
    "2. **Activate the environment:**\n",
    "\n",
    "    ```bash\n",
    "    conda activate exmed-bert\n",
    "    ```\n",
    "\n",
    "3. **Install additional required packages from `requirements.txt`:**\n",
    "\n",
    "    ```bash\n",
    "    pip install -r requirements.txt\n",
    "    ```\n",
    "\n",
    "---\n",
    "\n",
    "### Troubleshooting Environment Setup: Missing Packages\n",
    "\n",
    "If you encounter `ImportError` or `ModuleNotFoundError` messages after following the setup steps, it's possible that some packages failed to install during environment creation. This can happen due to network issues, version conflicts, or platform-specific constraints.\n",
    "\n",
    "**To resolve this, manually install the problematic package(s) using `pip`, referencing the version specified in `environment.yaml` or `requirements.txt`.**\n",
    "\n",
    "#### Steps to Fix Import Errors:\n",
    "\n",
    "1. **Ensure your Conda environment is active:**\n",
    "\n",
    "    ```bash\n",
    "    conda activate exmed-bert\n",
    "    ```\n",
    "\n",
    "2. **Manually install the missing package(s):**\n",
    "\n",
    "    Check the `environment.yaml` or `requirements.txt` for the correct version. Then run:\n",
    "\n",
    "    ```bash\n",
    "    pip install package_name==x.y.z\n",
    "    ```\n",
    "\n",
    "    **Example:**\n",
    "\n",
    "    ```bash\n",
    "    pip install torch==1.10.0+cu113\n",
    "    pip install transformers==4.12.0\n",
    "    ```\n",
    "\n",
    "Repeat this for any other packages that are causing errors.\n",
    "\n",
    "---\n",
    "\n",
    "### All the Configs for this Data Preparation are in `config.yaml`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f0213b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_length': 50,\n",
       " 'mask_drugs': True,\n",
       " 'delete_temporary_variables': True,\n",
       " 'split_sequence': True,\n",
       " 'drop_duplicates': True,\n",
       " 'converted_codes': False,\n",
       " 'convert_icd_to_phewas': False,\n",
       " 'convert_rxcui_to_atc': True,\n",
       " 'min_unmasked': 1,\n",
       " 'max_masked': 20,\n",
       " 'masked_lm_prob': 0.15,\n",
       " 'truncate': 'right',\n",
       " 'dynamic_masking': True,\n",
       " 'min_observations': 5,\n",
       " 'age_usage': 'year',\n",
       " 'use_cls': True,\n",
       " 'use_sep': False,\n",
       " 'valid_patient': True}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from datetime import date\n",
    "import yaml\n",
    "\n",
    "# Add the ExMed-BERT package to Python path for imports\n",
    "sys.path.append('./ExMed-BERT-main')\n",
    "\n",
    "# Get Master Config Params\n",
    "with open('config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "params = config['data_prep_params_example']\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9703e8",
   "metadata": {},
   "source": [
    "## 2. Encoding Classes: Dictionaries for Medical Data\n",
    "\n",
    "ExMed-BERT uses specialized dictionary classes to encode various types of patient data into integer IDs suitable for model input. These include:\n",
    "- `CodeDict`: Handles medical codes (ICD, PheWAS, RxNorm, ATC) and their mappings.\n",
    "- `AgeDict`: Bins and encodes patient ages.\n",
    "- `SexDict`: Encodes sex/gender.\n",
    "- `StateDict`: Encodes US state information.\n",
    "- `EndpointDict`: Encodes endpoint labels for classification tasks.\n",
    "\n",
    "__Note:__ We may want to enhance the `CodeDict` class to broaden its capabilities beyond Phecodes and RxNorm to include CPT codes and allow for the integration of other relevant coding systems as needed.\n",
    "\n",
    "Let's import these classes and briefly describe their roles. (It might take awhile the first time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c7c75e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from exmed_bert.data.encoding import (\n",
    "    AgeDict,     # Handles age binning and encoding\n",
    "    CodeDict,    # Handles medical codes (ICD, PheWAS, RxNorm, ATC)\n",
    "    SexDict,     # Handles sex/gender encoding\n",
    "    StateDict,   # Handles US state encoding\n",
    "    DICT_DEFAULTS,  # Default tokens (e.g., PAD, UNK, MASK)\n",
    "    EndpointDict # Handles endpoint label encoding (e.g., for classification tasks)\n",
    ")\n",
    "from exmed_bert.data.patient import Patient  # Main class for patient sequence processing\n",
    "from exmed_bert.data.dataset import PatientDataset  # Dataset class for batching patients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2389ea",
   "metadata": {},
   "source": [
    "### What do these classes do?\n",
    "- **CodeDict**: Maps raw medical codes (diagnoses, drugs) to integer IDs, handles code normalization (e.g., mapping RxNorm to ATC, ICD to PheWAS), and provides decoding for interpretability.\n",
    "- **AgeDict**: Bins ages (e.g., by year) and encodes them as IDs.\n",
    "- **SexDict**: Encodes sex/gender as IDs.\n",
    "- **StateDict**: Encodes US state abbreviations as IDs.\n",
    "- **EndpointDict**: Encodes outcome labels for supervised tasks.\n",
    "\n",
    "These dictionaries ensure that all categorical data is consistently mapped to integer IDs for model input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7197c94e",
   "metadata": {},
   "source": [
    "## 3. Example Code Dictionaries and Mappings\n",
    "\n",
    "For demonstration purposes, we define small example sets of codes and mappings. In our real model, these would be substantially larger and loaded from files within our own `data` directory. Given the current model state, the following files would be essential:\n",
    "\n",
    "* **`ATC_codes`**: We would likely utilize ATC5 codes to ensure the desired level of granularity.\n",
    "\n",
    "* **`phecodes`**: A approach may be to replace the traditional Phecode list with a comprehensive list of ICD codes.\n",
    "\n",
    "* __BELOW ARE POTENTIAL WAYS TO GET AROUND THE CURRENT \"MAPPING REQUIRMENTS\":__\n",
    "\n",
    "* **`RxNorm_to_ATC_mapping`**: Rather than a direct RxNorm to ATC mapping, we may opt to use generic molecule names as tokens. This can be achieved with a molecule-to-molecule map (e.g., `{'FINTEPLA': 'FINTEPLA', 'BIMZELX': 'BIMZELX'}`). We could also try and `NDC11` to `ATC5` map. We just want some way to get our ATC codes in here\n",
    "\n",
    "* **`ICD_to_Phecode_mapping`**: Similar to the RxNorm mapping, we can re-engineer this to function as an ICD-10 to ICD-10 map (e.g., `{'G40.81': 'G40.81', 'G40.812': 'G40.812'}`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19e7dfe",
   "metadata": {},
   "outputs": [],
   "source": "# Define new ATC codes (medications)\natc_codes = [\n    'A01AA01', 'B01AC06', 'C09AA05', 'D05AX02', 'E03AA01', 'F01BA01', 'G04BE03',\n    'H02AB02', 'J01CA04', 'K01AA02', 'L01XE01', 'M01AE01', 'N02BA01', 'O01AA01',\n    'P01AB01', 'Q01AA01', 'R03BA02', 'S01AA01', 'T01AA01', 'U01AA01', 'V01AA01'\n    ]\n\n# Define ICD codes (diagnoses) - using raw ICD-10 codes directly\nicd_codes = [\n    'I10', 'E11.9', 'Z51.11', 'K21.0', 'M17.9', 'E78.5', 'N18.3',\n    'A00', 'B00', 'C00', 'D00', 'E00', 'F00', 'G00', 'H00',\n    'J00', 'K00', 'L00', 'M00', 'N00'\n    ]\n\n# New RxNorm to ATC mapping. \n# ALL ATC CODES CAN BE FOUND IN THE ATC CODE LIST. THIS IS IMPORTANT\nrx_to_atc_map = {\n    '860975': 'A01AA01', '197361': 'B01AC06', '123456': 'C09AA05', '654321': 'D05AX02',\n    '789012': 'E03AA01', '345678': 'F01BA01', '987654': 'G04BE03',\n    '111111': 'H02AB02', '222222': 'J01CA04', '333333': 'K01AA02', '444444': 'L01XE01',\n    '555555': 'M01AE01', '666666': 'N02BA01', '777777': 'O01AA01', '888888': 'P01AB01',\n    '999999': 'Q01AA01', '121212': 'R03BA02', '131313': 'S01AA01', '141414': 'T01AA01',\n    '151515': 'U01AA01', '161616': 'V01AA01'\n    }\n\n# No longer needed - ICD codes are used directly without conversion\n\n# States for state encoding\nstate_list = ['CA', 'NY', 'TX', 'FL', 'IL', 'PA', 'OH', 'GA', 'NC', 'MI', 'WA', 'OR', 'CO', 'AZ', 'MA']"
  },
  {
   "cell_type": "markdown",
   "id": "3ca3c4c2",
   "metadata": {},
   "source": [
    "## 4. Initializing Encoding Dictionaries\n",
    "\n",
    "This section outlines the process of building our model's vocabulary, analogous to the tokenization phase in traditional NLP. ExMed-BERT handles patient data across five distinct \"modes\" or sequences:\n",
    "\n",
    "1.  **Code Sequence:** Medical codes (e.g., ICD, CPT, RxNorm, ATC).\n",
    "2.  **Sex Sequence:** Patient sex/gender information.\n",
    "3.  **State Sequence:** US state information.\n",
    "4.  **Age Sequence:** Patient age information.\n",
    "5.  **Visit Sequence:** This sequence is implicitly generated by ordering patient events based on their respective dates.\n",
    "\n",
    "For each of these modalities, we employ dedicated dictionary classes, each responsible for managing its own vocabulary. This ensures that vocabularies are kept separate and distinct across modalities.\n",
    "\n",
    "**Important Considerations:**\n",
    "\n",
    "* **Integer Mapping:** During this initialization, each unique medical code (or other data point) is mapped to a distinct integer ID. This integer serves as a unique identifier, or \"token,\" for that specific data element within the model.\n",
    "\n",
    "* **Learned Embeddings:** Later in the model's architecture, each of these unique tokens will be assigned its own learnable embedding, allowing the model to capture semantic relationships and context.\n",
    "\n",
    "* **Reserved Tokens:** The first six integer IDs are reserved for BERT's special tokens, defined as `DICT_DEFAULTS = [\"PAD\", \"UNK\", \"CLS\", \"SEP\", \"MASK\", \"NA\"]`. These special tokens serve various purposes, such as padding sequences to a uniform length (`PAD`), handling unknown tokens (`UNK`), marking the beginning of a sequence (`CLS`), separating segments (`SEP`), masking tokens for pre-training (`MASK`), and indicating not applicable data (`NA`).\n",
    "\n",
    "* **Modality-Specific Vocabularies:** To reiterate, the vocabularies are __*not*__ mixed together. __Each dictionary class maintains a separate set of vocabulary__ and mappings for its respective modality, allowing ExMed-BERT to process and learn from these distinct data types independently yet cohesively within the model's architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2562862f",
   "metadata": {},
   "outputs": [],
   "source": "# Code dictionary for medical codes - using ICD codes directly\ncode_dict = CodeDict(\n    atc_codes=atc_codes,\n    icd_codes=icd_codes,\n    rx_to_atc_map=rx_to_atc_map\n)\n\n# Age dictionary for binning and encoding ages (by year)\n# You can customize the binsize. I chose yearly age bins from 0 to 90: [0, 1, 2, ..., 90]\nage_dict = AgeDict(max_age=90, min_age=0, binsize=1)\n# Convert the age_dict's vocabulary to string for consistency\nage_dict.vocab = [str(int(float(age))) if age not in DICT_DEFAULTS else age for age in age_dict.vocab]\nage_dict.labels_to_id = {(str(int(float(label))) if label not in DICT_DEFAULTS else label): idx \n                        for label, idx in age_dict.labels_to_id.items()}\nage_dict.ids_to_label = {idx: (str(int(float(label))) if label not in DICT_DEFAULTS else label)\n                        for idx, label in age_dict.ids_to_label.items()}\n\n# Sex dictionary\nsex_dict = SexDict(sex=['MALE', 'FEMALE'])\n\n# State dictionary\nstate_dict = StateDict(states=state_list)"
  },
  {
   "cell_type": "markdown",
   "id": "f64039ee",
   "metadata": {},
   "source": [
    "## 5. Example Patient Data Structure\n",
    "\n",
    "To illustrate the input format, let's examine the structure of patient data that ExMed-BERT will process. Each patient's record will primarily consist of sequences of events, where diagnoses and drug administrations are time-stamped.\n",
    "\n",
    "It's crucial to ensure that the following core demographic and clinical data points are included for each patient:\n",
    "\n",
    "* **Diagnosis Codes:** A chronological list of all recorded diagnosis codes (e.g., PheWAS).\n",
    "\n",
    "* **Diagnosis Dates:** The corresponding dates for each diagnosis, maintaining a direct index-level alignment with the `Diagnosis Codes` list.\n",
    "\n",
    "* **Drug Codes:** A chronological list of administered drug codes (e.g., RxNorm CUI or generic molecule names).\n",
    "\n",
    "* **Drug Dates:** The corresponding dates for each drug administration, also maintaining index-level alignment with the `Drug Codes` list.\n",
    "\n",
    "* **Birth Year:** The patient's year of birth.\n",
    "\n",
    "* **Sex:** The patient's sex (e.g., \"Male,\" \"Female\").\n",
    "\n",
    "* **Patient State:** The patient's US state of residence.\n",
    "\n",
    "**Example Illustration:**\n",
    "\n",
    "Consider patient `10000`. Their data might appear as follows:\n",
    "\n",
    "* **Diagnosis Codes:** `['A00', 'G00']`\n",
    "\n",
    "* **Diagnosis Dates:** `['2021-01-01', '2021-01-07']`\n",
    "\n",
    "* **Drug Codes:** `['111111', '222222']`\n",
    "\n",
    "* **Drug Dates:** `['2021-02-01', '2021-02-02']`\n",
    "\n",
    "This structure ensures that for a specific patient, the diagnosis at index `i` in `diagnosis_codes` occurred on the date at index `i` in `diagnosis_dates`. Similarly, for drug administrations.\n",
    "\n",
    "**Note on PLOS (Prolonged Length of Stay):**\n",
    "\n",
    "While \"Prolonged Length of Stay\" (PLOS) is a significant clinical outcome, pre-training typically focuses on learning general representations from large volumes of unlabeled medical text and codes. ExMed-BERT used PLOS during pretraining as it was helpful for their specific use case of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "194df3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = [\n",
    "    {\n",
    "        'patient_id': 10000,\n",
    "        'diagnoses': ['A00', 'B00', 'C00', 'D00', 'E00', 'F00', 'G00'],\n",
    "        'diagnosis_dates': [date(2021, 1, 1), date(2021, 1, 2), date(2021, 1, 3), date(2021, 1, 4), date(2021, 1, 5), date(2021, 1, 6), date(2021, 1, 7)],\n",
    "        'drugs': ['111111', '222222', '333333', '444444', '555555', '666666', '777777'],\n",
    "        'prescription_dates': [date(2021, 2, 1), date(2021, 2, 2), date(2021, 2, 3), date(2021, 2, 4), date(2021, 2, 5), date(2021, 2, 6), date(2021, 2, 7)],\n",
    "        'birth_year': 1980,\n",
    "        'sex': 'MALE',\n",
    "        'patient_state': 'CA',\n",
    "        'plos': 1\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10001,\n",
    "        'diagnoses': ['H00', 'J00', 'K00', 'L00', 'M00', 'N00', 'I10'],\n",
    "        'diagnosis_dates': [date(2021, 1, 8), date(2021, 1, 9), date(2021, 1, 10), date(2021, 1, 11), date(2021, 1, 12), date(2021, 1, 13), date(2021, 1, 14)],\n",
    "        'drugs': ['888888', '999999', '121212', '131313', '141414', '151515', '161616'],\n",
    "        'prescription_dates': [date(2021, 2, 8), date(2021, 2, 9), date(2021, 2, 10), date(2021, 2, 11), date(2021, 2, 12), date(2021, 2, 13), date(2021, 2, 14)],\n",
    "        'birth_year': 1975,\n",
    "        'sex': 'FEMALE',\n",
    "        'patient_state': 'NY',\n",
    "        'plos': 0\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10002,\n",
    "        'diagnoses': ['E11.9', 'Z51.11', 'K21.0', 'M17.9', 'E78.5', 'N18.3', 'A00'],\n",
    "        'diagnosis_dates': [date(2021, 3, 1), date(2021, 3, 2), date(2021, 3, 3), date(2021, 3, 4), date(2021, 3, 5), date(2021, 3, 6), date(2021, 3, 7)],\n",
    "        'drugs': ['860975', '197361', '123456', '654321', '789012', '345678', '987654'],\n",
    "        'prescription_dates': [date(2021, 4, 1), date(2021, 4, 2), date(2021, 4, 3), date(2021, 4, 4), date(2021, 4, 5), date(2021, 4, 6), date(2021, 4, 7)],\n",
    "        'birth_year': 1990,\n",
    "        'sex': 'MALE',\n",
    "        'patient_state': 'TX',\n",
    "        'plos': 1\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10003,\n",
    "        'diagnoses': ['B00', 'C00', 'D00', 'E00', 'F00', 'G00', 'H00'],\n",
    "        'diagnosis_dates': [date(2021, 5, 1), date(2021, 5, 2), date(2021, 5, 3), date(2021, 5, 4), date(2021, 5, 5), date(2021, 5, 6), date(2021, 5, 7)],\n",
    "        'drugs': ['222222', '333333', '444444', '555555', '666666', '777777', '888888'],\n",
    "        'prescription_dates': [date(2021, 6, 1), date(2021, 6, 2), date(2021, 6, 3), date(2021, 6, 4), date(2021, 6, 5), date(2021, 6, 6), date(2021, 6, 7)],\n",
    "        'birth_year': 1985,\n",
    "        'sex': 'FEMALE',\n",
    "        'patient_state': 'FL',\n",
    "        'plos': 0\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10004,\n",
    "        'diagnoses': ['J00', 'K00', 'L00', 'M00', 'N00', 'I10', 'E11.9'],\n",
    "        'diagnosis_dates': [date(2021, 7, 1), date(2021, 7, 2), date(2021, 7, 3), date(2021, 7, 4), date(2021, 7, 5), date(2021, 7, 6), date(2021, 7, 7)],\n",
    "        'drugs': ['999999', '121212', '131313', '141414', '151515', '161616', '860975'],\n",
    "        'prescription_dates': [date(2021, 8, 1), date(2021, 8, 2), date(2021, 8, 3), date(2021, 8, 4), date(2021, 8, 5), date(2021, 8, 6), date(2021, 8, 7)],\n",
    "        'birth_year': 1970,\n",
    "        'sex': 'MALE',\n",
    "        'patient_state': 'IL',\n",
    "        'plos': 1\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10005,\n",
    "        'diagnoses': ['Z51.11', 'K21.0', 'M17.9', 'E78.5', 'N18.3', 'A00', 'B00'],\n",
    "        'diagnosis_dates': [date(2021, 9, 1), date(2021, 9, 2), date(2021, 9, 3), date(2021, 9, 4), date(2021, 9, 5), date(2021, 9, 6), date(2021, 9, 7)],\n",
    "        'drugs': ['197361', '123456', '654321', '789012', '345678', '987654', '222222'],\n",
    "        'prescription_dates': [date(2021, 10, 1), date(2021, 10, 2), date(2021, 10, 3), date(2021, 10, 4), date(2021, 10, 5), date(2021, 10, 6), date(2021, 10, 7)],\n",
    "        'birth_year': 2000,\n",
    "        'sex': 'FEMALE',\n",
    "        'patient_state': 'PA',\n",
    "        'plos': 0\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10006,\n",
    "        'diagnoses': ['C00', 'D00', 'E00', 'F00', 'G00', 'H00', 'J00'],\n",
    "        'diagnosis_dates': [date(2021, 11, 1), date(2021, 11, 2), date(2021, 11, 3), date(2021, 11, 4), date(2021, 11, 5), date(2021, 11, 6), date(2021, 11, 7)],\n",
    "        'drugs': ['333333', '444444', '555555', '666666', '777777', '888888', '999999'],\n",
    "        'prescription_dates': [date(2021, 12, 1), date(2021, 12, 2), date(2021, 12, 3), date(2021, 12, 4), date(2021, 12, 5), date(2021, 12, 6), date(2021, 12, 7)],\n",
    "        'birth_year': 1995,\n",
    "        'sex': 'MALE',\n",
    "        'patient_state': 'OH',\n",
    "        'plos': 1\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10007,\n",
    "        'diagnoses': ['K00', 'L00', 'M00', 'N00', 'I10', 'E11.9', 'Z51.11'],\n",
    "        'diagnosis_dates': [date(2022, 1, 1), date(2022, 1, 2), date(2022, 1, 3), date(2022, 1, 4), date(2022, 1, 5), date(2022, 1, 6), date(2022, 1, 7)],\n",
    "        'drugs': ['121212', '131313', '141414', '151515', '161616', '860975', '197361'],\n",
    "        'prescription_dates': [date(2022, 2, 1), date(2022, 2, 2), date(2022, 2, 3), date(2022, 2, 4), date(2022, 2, 5), date(2022, 2, 6), date(2022, 2, 7)],\n",
    "        'birth_year': 1988,\n",
    "        'sex': 'FEMALE',\n",
    "        'patient_state': 'GA',\n",
    "        'plos': 0\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10008,\n",
    "        'diagnoses': ['K21.0', 'M17.9', 'E78.5', 'N18.3', 'A00', 'B00', 'C00'],\n",
    "        'diagnosis_dates': [date(2022, 3, 1), date(2022, 3, 2), date(2022, 3, 3), date(2022, 3, 4), date(2022, 3, 5), date(2022, 3, 6), date(2022, 3, 7)],\n",
    "        'drugs': ['123456', '654321', '789012', '345678', '987654', '222222', '333333'],\n",
    "        'prescription_dates': [date(2022, 4, 1), date(2022, 4, 2), date(2022, 4, 3), date(2022, 4, 4), date(2022, 4, 5), date(2022, 4, 6), date(2022, 4, 7)],\n",
    "        'birth_year': 1978,\n",
    "        'sex': 'MALE',\n",
    "        'patient_state': 'NC',\n",
    "        'plos': 1\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10009,\n",
    "        'diagnoses': ['D00', 'E00', 'F00', 'G00', 'H00', 'J00', 'K00'],\n",
    "        'diagnosis_dates': [date(2022, 5, 1), date(2022, 5, 2), date(2022, 5, 3), date(2022, 5, 4), date(2022, 5, 5), date(2022, 5, 6), date(2022, 5, 7)],\n",
    "        'drugs': ['444444', '555555', '666666', '777777', '888888', '999999', '121212'],\n",
    "        'prescription_dates': [date(2022, 6, 1), date(2022, 6, 2), date(2022, 6, 3), date(2022, 6, 4), date(2022, 6, 5), date(2022, 6, 6), date(2022, 6, 7)],\n",
    "        'birth_year': 1982,\n",
    "        'sex': 'FEMALE',\n",
    "        'patient_state': 'MI',\n",
    "        'plos': 0\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10010,\n",
    "        'diagnoses': ['L00', 'M00', 'N00', 'I10', 'E11.9', 'Z51.11', 'K21.0'],\n",
    "        'diagnosis_dates': [date(2022, 7, 1), date(2022, 7, 2), date(2022, 7, 3), date(2022, 7, 4), date(2022, 7, 5), date(2022, 7, 6), date(2022, 7, 7)],\n",
    "        'drugs': ['131313', '141414', '151515', '161616', '860975', '197361', '123456'],\n",
    "        'prescription_dates': [date(2022, 8, 1), date(2022, 8, 2), date(2022, 8, 3), date(2022, 8, 4), date(2022, 8, 5), date(2022, 8, 6), date(2022, 8, 7)],\n",
    "        'birth_year': 1992,\n",
    "        'sex': 'MALE',\n",
    "        'patient_state': 'WA',\n",
    "        'plos': 1\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10011,\n",
    "        'diagnoses': ['M17.9', 'E78.5', 'N18.3', 'A00', 'B00', 'C00', 'D00'],\n",
    "        'diagnosis_dates': [date(2022, 9, 1), date(2022, 9, 2), date(2022, 9, 3), date(2022, 9, 4), date(2022, 9, 5), date(2022, 9, 6), date(2022, 9, 7)],\n",
    "        'drugs': ['654321', '789012', '345678', '987654', '222222', '333333', '444444'],\n",
    "        'prescription_dates': [date(2022, 10, 1), date(2022, 10, 2), date(2022, 10, 3), date(2022, 10, 4), date(2022, 10, 5), date(2022, 10, 6), date(2022, 10, 7)],\n",
    "        'birth_year': 1987,\n",
    "        'sex': 'FEMALE',\n",
    "        'patient_state': 'OR',\n",
    "        'plos': 0\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10012,\n",
    "        'diagnoses': ['E78.5', 'N18.3', 'A00', 'B00', 'C00', 'D00', 'E00'],\n",
    "        'diagnosis_dates': [date(2022, 11, 1), date(2022, 11, 2), date(2022, 11, 3), date(2022, 11, 4), date(2022, 11, 5), date(2022, 11, 6), date(2022, 11, 7)],\n",
    "        'drugs': ['789012', '345678', '987654', '222222', '333333', '444444', '555555'],\n",
    "        'prescription_dates': [date(2022, 12, 1), date(2022, 12, 2), date(2022, 12, 3), date(2022, 12, 4), date(2022, 12, 5), date(2022, 12, 6), date(2022, 12, 7)],\n",
    "        'birth_year': 1998,\n",
    "        'sex': 'MALE',\n",
    "        'patient_state': 'CO',\n",
    "        'plos': 1\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10013,\n",
    "        'diagnoses': ['N18.3', 'A00', 'B00', 'C00', 'D00', 'E00', 'F00'],\n",
    "        'diagnosis_dates': [date(2023, 1, 1), date(2023, 1, 2), date(2023, 1, 3), date(2023, 1, 4), date(2023, 1, 5), date(2023, 1, 6), date(2023, 1, 7)],\n",
    "        'drugs': ['345678', '987654', '222222', '333333', '444444', '555555', '666666'],\n",
    "        'prescription_dates': [date(2023, 2, 1), date(2023, 2, 2), date(2023, 2, 3), date(2023, 2, 4), date(2023, 2, 5), date(2023, 2, 6), date(2023, 2, 7)],\n",
    "        'birth_year': 1983,\n",
    "        'sex': 'FEMALE',\n",
    "        'patient_state': 'AZ',\n",
    "        'plos': 0\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10014,\n",
    "        'diagnoses': ['A00', 'B00', 'C00', 'D00', 'E00', 'F00', 'G00'],\n",
    "        'diagnosis_dates': [date(2023, 3, 1), date(2023, 3, 2), date(2023, 3, 3), date(2023, 3, 4), date(2023, 3, 5), date(2023, 3, 6), date(2023, 3, 7)],\n",
    "        'drugs': ['987654', '222222', '333333', '444444', '555555', '666666', '777777'],\n",
    "        'prescription_dates': [date(2023, 4, 1), date(2023, 4, 2), date(2023, 4, 3), date(2023, 4, 4), date(2023, 4, 5), date(2023, 4, 6), date(2023, 4, 7)],\n",
    "        'birth_year': 1993,\n",
    "        'sex': 'MALE',\n",
    "        'patient_state': 'MA',\n",
    "        'plos': 1\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10015,\n",
    "        'diagnoses': ['B00', 'C00', 'D00', 'E00', 'F00', 'G00', 'H00'],\n",
    "        'diagnosis_dates': [date(2023, 5, 1), date(2023, 5, 2), date(2023, 5, 3), date(2023, 5, 4), date(2023, 5, 5), date(2023, 5, 6), date(2023, 5, 7)],\n",
    "        'drugs': ['222222', '333333', '444444', '555555', '666666', '777777', '888888'],\n",
    "        'prescription_dates': [date(2023, 6, 1), date(2023, 6, 2), date(2023, 6, 3), date(2023, 6, 4), date(2023, 6, 5), date(2023, 6, 6), date(2023, 6, 7)],\n",
    "        'birth_year': 1986,\n",
    "        'sex': 'FEMALE',\n",
    "        'patient_state': 'CA',\n",
    "        'plos': 0\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10016,\n",
    "        'diagnoses': ['J00', 'K00', 'L00', 'M00', 'N00', 'I10', 'E11.9'],\n",
    "        'diagnosis_dates': [date(2023, 7, 1), date(2023, 7, 2), date(2023, 7, 3), date(2023, 7, 4), date(2023, 7, 5), date(2023, 7, 6), date(2023, 7, 7)],\n",
    "        'drugs': ['999999', '121212', '131313', '141414', '151515', '161616', '860975'],\n",
    "        'prescription_dates': [date(2023, 8, 1), date(2023, 8, 2), date(2023, 8, 3), date(2023, 8, 4), date(2023, 8, 5), date(2023, 8, 6), date(2023, 8, 7)],\n",
    "        'birth_year': 1971,\n",
    "        'sex': 'MALE',\n",
    "        'patient_state': 'NY',\n",
    "        'plos': 1\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10017,\n",
    "        'diagnoses': ['E11.9', 'Z51.11', 'K21.0', 'M17.9', 'E78.5', 'N18.3', 'A00'],\n",
    "        'diagnosis_dates': [date(2023, 9, 1), date(2023, 9, 2), date(2023, 9, 3), date(2023, 9, 4), date(2023, 9, 5), date(2023, 9, 6), date(2023, 9, 7)],\n",
    "        'drugs': ['860975', '197361', '123456', '654321', '789012', '345678', '987654'],\n",
    "        'prescription_dates': [date(2023, 10, 1), date(2023, 10, 2), date(2023, 10, 3), date(2023, 10, 4), date(2023, 10, 5), date(2023, 10, 6), date(2023, 10, 7)],\n",
    "        'birth_year': 1991,\n",
    "        'sex': 'FEMALE',\n",
    "        'patient_state': 'TX',\n",
    "        'plos': 0\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10018,\n",
    "        'diagnoses': ['B00', 'C00', 'D00', 'E11.9', 'F00', 'G00', 'H00'],\n",
    "        'diagnosis_dates': [date(2023, 11, 1), date(2023, 11, 2), date(2023, 11, 3), date(2023, 11, 4), date(2023, 11, 5), date(2023, 11, 6), date(2023, 11, 7)],\n",
    "        'drugs': ['222222', '333333', '444444', '555555', '666666', '777777', '888888'],\n",
    "        'prescription_dates': [date(2023, 12, 1), date(2023, 12, 2), date(2023, 12, 3), date(2023, 12, 4), date(2023, 12, 5), date(2023, 12, 6), date(2023, 12, 7)],\n",
    "        'birth_year': 1984,\n",
    "        'sex': 'MALE',\n",
    "        'patient_state': 'FL',\n",
    "        'plos': 1\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10019,\n",
    "        'diagnoses': ['J00', 'K00', 'L00', 'M00', 'N00', 'I10', 'E11.9'],\n",
    "        'diagnosis_dates': [date(2024, 1, 1), date(2024, 1, 2), date(2024, 1, 3), date(2024, 1, 4), date(2024, 1, 5), date(2024, 1, 6), date(2024, 1, 7)],\n",
    "        'drugs': ['999999', '121212', '131313', '141414', '151515', '161616', '860975'],\n",
    "        'prescription_dates': [date(2024, 2, 1), date(2024, 2, 2), date(2024, 2, 3), date(2024, 2, 4), date(2024, 2, 5), date(2024, 2, 6), date(2024, 2, 7)],\n",
    "        'birth_year': 1972,\n",
    "        'sex': 'FEMALE',\n",
    "        'patient_state': 'IL',\n",
    "        'plos': 0\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10020,\n",
    "        'diagnoses': ['Z51.11', 'K21.0', 'M17.9', 'E78.5', 'N18.3', 'A00', 'B00'],\n",
    "        'diagnosis_dates': [date(2024, 3, 1), date(2024, 3, 2), date(2024, 3, 3), date(2024, 3, 4), date(2024, 3, 5), date(2024, 3, 6), date(2024, 3, 7)],\n",
    "        'drugs': ['197361', '123456', '654321', '789012', '345678', '987654', '222222'],\n",
    "        'prescription_dates': [date(2024, 4, 1), date(2024, 4, 2), date(2024, 4, 3), date(2024, 4, 4), date(2024, 4, 5), date(2024, 4, 6), date(2024, 4, 7)],\n",
    "        'birth_year': 2001,\n",
    "        'sex': 'MALE',\n",
    "        'patient_state': 'PA',\n",
    "        'plos': 1\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10021,\n",
    "        'diagnoses': ['C00', 'D00', 'E00', 'F00', 'G00', 'H00', 'J00'],\n",
    "        'diagnosis_dates': [date(2024, 5, 1), date(2024, 5, 2), date(2024, 5, 3), date(2024, 5, 4), date(2024, 5, 5), date(2024, 5, 6), date(2024, 5, 7)],\n",
    "        'drugs': ['333333', '444444', '555555', '666666', '777777', '888888', '999999'],\n",
    "        'prescription_dates': [date(2024, 6, 1), date(2024, 6, 2), date(2024, 6, 3), date(2024, 6, 4), date(2024, 6, 5), date(2024, 6, 6), date(2024, 6, 7)],\n",
    "        'birth_year': 1996,\n",
    "        'sex': 'FEMALE',\n",
    "        'patient_state': 'OH',\n",
    "        'plos': 0\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10022,\n",
    "        'diagnoses': ['K00', 'L00', 'M00', 'N00', 'I10', 'E11.9', 'Z51.11'],\n",
    "        'diagnosis_dates': [date(2024, 7, 1), date(2024, 7, 2), date(2024, 7, 3), date(2024, 7, 4), date(2024, 7, 5), date(2024, 7, 6), date(2024, 7, 7)],\n",
    "        'drugs': ['121212', '131313', '141414', '151515', '161616', '860975', '197361'],\n",
    "        'prescription_dates': [date(2024, 8, 1), date(2024, 8, 2), date(2024, 8, 3), date(2024, 8, 4), date(2024, 8, 5), date(2024, 8, 6), date(2024, 8, 7)],\n",
    "        'birth_year': 1989,\n",
    "        'sex': 'MALE',\n",
    "        'patient_state': 'GA',\n",
    "        'plos': 1\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10023,\n",
    "        'diagnoses': ['K21.0', 'M17.9', 'E78.5', 'N18.3', 'A00', 'B00', 'C00'],\n",
    "        'diagnosis_dates': [date(2024, 9, 1), date(2024, 9, 2), date(2024, 9, 3), date(2024, 9, 4), date(2024, 9, 5), date(2024, 9, 6), date(2024, 9, 7)],\n",
    "        'drugs': ['123456', '654321', '789012', '345678', '987654', '222222', '333333'],\n",
    "        'prescription_dates': [date(2024, 10, 1), date(2024, 10, 2), date(2024, 10, 3), date(2024, 10, 4), date(2024, 10, 5), date(2024, 10, 6), date(2024, 10, 7)],\n",
    "        'birth_year': 1979,\n",
    "        'sex': 'FEMALE',\n",
    "        'patient_state': 'NC',\n",
    "        'plos': 0\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10024,\n",
    "        'diagnoses': ['D00', 'E00', 'F00', 'G00', 'H00', 'J00', 'K00'],\n",
    "        'diagnosis_dates': [date(2024, 11, 1), date(2024, 11, 2), date(2024, 11, 3), date(2024, 11, 4), date(2024, 11, 5), date(2024, 11, 6), date(2024, 11, 7)],\n",
    "        'drugs': ['444444', '555555', '666666', '777777', '888888', '999999', '121212'],\n",
    "        'prescription_dates': [date(2024, 12, 1), date(2024, 12, 2), date(2024, 12, 3), date(2024, 12, 4), date(2024, 12, 5), date(2024, 12, 6), date(2024, 12, 7)],\n",
    "        'birth_year': 1981,\n",
    "        'sex': 'MALE',\n",
    "        'patient_state': 'MI',\n",
    "        'plos': 1\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10025,\n",
    "        'diagnoses': ['L00', 'M00', 'N00', 'I10', 'E11.9', 'Z51.11', 'K21.0'],\n",
    "        'diagnosis_dates': [date(2025, 1, 1), date(2025, 1, 2), date(2025, 1, 3), date(2025, 1, 4), date(2025, 1, 5), date(2025, 1, 6), date(2025, 1, 7)],\n",
    "        'drugs': ['131313', '141414', '151515', '161616', '860975', '197361', '123456'],\n",
    "        'prescription_dates': [date(2025, 2, 1), date(2025, 2, 2), date(2025, 2, 3), date(2025, 2, 4), date(2025, 2, 5), date(2025, 2, 6), date(2025, 2, 7)],\n",
    "        'birth_year': 1994,\n",
    "        'sex': 'FEMALE',\n",
    "        'patient_state': 'WA',\n",
    "        'plos': 0\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10026,\n",
    "        'diagnoses': ['M17.9', 'E78.5', 'N18.3', 'A00', 'B00', 'C00', 'D00'],\n",
    "        'diagnosis_dates': [date(2025, 3, 1), date(2025, 3, 2), date(2025, 3, 3), date(2025, 3, 4), date(2025, 3, 5), date(2025, 3, 6), date(2025, 3, 7)],\n",
    "        'drugs': ['654321', '789012', '345678', '987654', '222222', '333333', '444444'],\n",
    "        'prescription_dates': [date(2025, 4, 1), date(2025, 4, 2), date(2025, 4, 3), date(2025, 4, 4), date(2025, 4, 5), date(2025, 4, 6), date(2025, 4, 7)],\n",
    "        'birth_year': 1997,\n",
    "        'sex': 'MALE',\n",
    "        'patient_state': 'OR',\n",
    "        'plos': 1\n",
    "    },\n",
    "    {\n",
    "        'patient_id': 10027,\n",
    "        'diagnoses': ['E78.5', 'N18.3', 'A00', 'B00', 'C00', 'D00', 'E00'],\n",
    "        'diagnosis_dates': [date(2025, 5, 1), date(2025, 5, 2), date(2025, 5, 3), date(2025, 5, 4), date(2025, 5, 5), date(2025, 5, 6), date(2025, 5, 7)],\n",
    "        'drugs': ['789012', '345678', '987654', '222222', '333333', '444444', '555555'],\n",
    "        'prescription_dates': [date(2025, 6, 1), date(2025, 6, 2), date(2025, 6, 3), date(2025, 6, 4), date(2025, 6, 5), date(2025, 6, 6), date(2025, 6, 7)],\n",
    "        'birth_year': 1999,\n",
    "        'sex': 'FEMALE',\n",
    "        'patient_state': 'CO',\n",
    "        'plos': 0\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1399813",
   "metadata": {},
   "source": [
    "## 6. Patient Object: Encoding and Processing __EXAMPLE FOR SHOW__\n",
    "\n",
    "The `Patient` class is central to preparing raw patient data for the model. It handles the encoding of various data points using predefined dictionaries (like `CodeDict`, `SexDict`, `AgeDict`, `StateDict`), and orchestrates critical preprocessing steps such as masking for Masked Language Modeling (MLM) and sequence truncation/padding. Essentially, it transforms a patient's raw medical record into a structured, numerical format that can be directly fed into a deep learning model.\n",
    "\n",
    "This class manages patient data, incorporates vocabulary definitions, and applies various configurable model parameters to construct the input sequences. The examples below show the patient sequence *after* masking has been performed.\n",
    "\n",
    "Let's look at some important parameters and outputs:\n",
    "\n",
    "### Key Patient Class Parameters:\n",
    "\n",
    "* **`max_length`**: Defines the maximum number of codes (or patient events) allowed in the sequence. Sequences longer than this will be truncated, and shorter ones will be padded.\n",
    "\n",
    "* **`mask_drugs`**: A boolean flag that, when `True`, enables the masking of drug codes during the MLM pre-training task. This allows the model to learn to predict drug codes from their context. This can be extended to other code types if desired.\n",
    "\n",
    "* **`drop_duplicates`**: When set to `True` (recommended), this parameter ensures that only unique codes occurring on the exact same `time_point` (date) are retained, preventing redundancy in concurrent events.\n",
    "\n",
    "* **`converted_codes`**: This boolean flag indicates whether the input diagnosis and drug codes provided to the `Patient` object have already been converted to their target format (e.g., PheWAS, ATC).\n",
    "    * If `True`, the class skips its internal conversion functions, assuming codes are pre-processed.\n",
    "    * If `False`, it signals that input codes may require transformation based on `convert_icd_to_phewas` and `convert_rxcui_to_atc` flags.\n",
    "\n",
    "* **`convert_icd_to_phewas`**: When `True` (and `converted_codes` is `False`), ICD diagnosis codes will be mapped to PheWAS codes during processing. If `False`, ICD codes remain as-is.\n",
    "\n",
    "* **`convert_rxcui_to_atc`**: When `True` (and `converted_codes` is `False`), RxCUI drug codes will be transformed into ATC codes. If `False`, RxCUI codes remain in their original format.\n",
    "\n",
    "* **`dynamic_masking`**: Setting this to `True` is recommended as it ensures that different codes are masked on each iteration (or epoch). This prevents the model from memorizing a fixed set of masked tokens and improves generalization.\n",
    "\n",
    "* **`age_usage`**: Specifies the unit for age representation (e.g., \"year\", \"months\", \"decimal\"). This aligns with how age values are defined in the `AgeDict`.\n",
    "\n",
    "### Model Input Modalities (from `patient.get_patient_data()`):\n",
    "\n",
    "After initializing and processing a `Patient` object, calling `model_input = patient.get_patient_data()` retrieves a dictionary containing various sequences (modalities) ready for model consumption.\n",
    "\n",
    "* **`input_ids`**: A tensor or list containing the numerical IDs of the PheWAS and ATC codes in the patient's sequence. Special reserved BERT tokens (`0-5`) are used for specific purposes (e.g., `[CLS]`, `[MASK]`, `[PAD]`). You will see many `0`s at the end of sequences, which are `PAD` tokens used to ensure all patient sequences conform to the `max_length`.\n",
    "    * **Example from data:** `tensor([ 2, 31, 32, 33, 34, 4, 36, 37, 9, 10, 11, 12, 32, 15, 16, 0, ...])`\n",
    "    * **Decoded Example:** `['CLS', '715.2', '272.1', '585.3', '800', 'MASK', '1000', '1100', 'D05AX02', 'E03AA01', 'F01BA01', 'G04BE03', '272.1', 'K01AA02', 'L01XE01', 'PAD', ...]`\n",
    "\n",
    "* **`entity_ids`**: A tensor indicating the type of `input_id` code at each index. This helps the model differentiate between code categories.\n",
    "    * `default`: Used for special BERT tokens (e.g., `[CLS]`, `[PAD]`).\n",
    "    * `atc`: Denotes an ATC (drug) code.\n",
    "    * `phewas`: Denotes a PheWAS (diagnosis) code.\n",
    "    * **Example from data:** `tensor([0, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, ...])`\n",
    "    * **Decoded Example:** `['default', 'phewas', 'phewas', 'phewas', 'phewas', 'phewas', 'phewas', 'phewas', 'atc', 'atc', 'atc', 'atc', 'atc', 'atc', 'atc', 'default', ...]`\n",
    "\n",
    "* **`sex_ids`**: A tensor representing the patient's biological sex, constant across all active tokens in the sequence.\n",
    "    * **Example from data:** `tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, ...])`\n",
    "    * **Decoded Example:** `['MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'MALE', 'PAD', ...]`\n",
    "\n",
    "* **`state_ids`**: A tensor holding the patient's state of residence, constant across all active tokens.\n",
    "    * **Example from data:** `tensor([13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 0, ...])`\n",
    "    * **Decoded Example:** `['OR', 'OR', 'OR', 'OR', 'OR', 'OR', 'OR', 'OR', 'OR', 'OR', 'OR', 'OR', 'OR', 'OR', 'OR', 'PAD', ...]`\n",
    "\n",
    "* **`age_ids`**: A tensor representing the patient's age (often binned or quantized), constant across all active tokens.\n",
    "    * **Example from data:** `tensor([30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 0, ...])`\n",
    "    * **Decoded Example:** `['28', '28', '28', '28', '28', '28', '28', '28', '28', '28', '28', '28', '28', '28', '28', 'PAD', ...]`\n",
    "\n",
    "* **`attention_mask`**: A critical tensor for transformer models, indicating which parts of the input sequence are \"real\" data and which are padding.\n",
    "    * `1`: Indicates an active, non-padded token that the model should attend to.\n",
    "    * `0`: Indicates a padded token that the model should ignore during attention calculations.\n",
    "    * **Example from data:** `tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...])`\n",
    "\n",
    "* **`position_ids`**: This tensor provides positional information to the model, enabling it to understand the chronological order of events within the sequence.\n",
    "    * If two or more medical events share the same `position_id`, it indicates that they occurred on the same day or within the same visit.\n",
    "    * **Example from data:** `tensor([ 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0, ...])`\n",
    "\n",
    "* **`code_labels`**: This tensor is specifically used for the Masked Language Model (MLM) pre-training task. It holds the *original IDs* of the tokens that were masked in `input_ids`.\n",
    "    * `-100`: This is a common convention in PyTorch to signify that a particular position should be ignored when calculating the loss (i.e., this token was not masked, or it's a special token that shouldn't be predicted).\n",
    "\n",
    "    * For example, if `input_ids` has `4` (the `[MASK]` token) at index 5, then `code_labels` at index 5 will contain the original numerical ID of the code that was masked (e.g., `35`, which decodes to `'900'`). If a token was replaced by a *random* token from the vocabulary (another part of BERT's masking strategy), `code_labels` will hold the ID of the *original* token before the replacement.\n",
    "    \n",
    "    * **Example from data:** `tensor([-100, -100, -100, -100, -100, 35, -100, -100, -100, -100, -100, -100, 14, -100, -100, -100, ...])`\n",
    "    * **Decoded Example:** `[None, None, None, None, None, '900', None, None, None, None, None, None, 'J01CA04', None, None, None, ...]` (where `J01CA04` was the original value at that position before replacement/masking)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9501db",
   "metadata": {},
   "outputs": [],
   "source": "for idx, patient_data in enumerate(patients, 1):\n    try:\n        # Remove endpoint_labels since they're not needed for pretraining\n        patient = Patient(\n            patient_id=patient_data['patient_id'],            # Unique identifier for tracking and referencing individual patients in the dataset\n            diagnoses=patient_data['diagnoses'],            # List of ICD diagnosis codes used directly without conversion\n            drugs=patient_data['drugs'],                    # List of RxNorm drug codes that will be converted to ATC for standardization\n            diagnosis_dates=patient_data['diagnosis_dates'], # Timestamps for diagnoses to maintain temporal order in sequence modeling\n            prescription_dates=patient_data['prescription_dates'], # Timestamps for prescriptions to maintain temporal order\n            birth_year=patient_data['birth_year'],           # Used to calculate patient age for age-based feature encoding\n            sex=patient_data['sex'],                         # Demographic feature encoded as MALE/FEMALE for patient characterization\n            patient_state=patient_data['patient_state'],     # Geographic feature for potential regional health pattern analysis\n            max_length=params['max_length'],                                   # Maximum sequence length - truncates or pads sequences for consistent model input\n            code_embed=code_dict,                            # Handles conversion and encoding of medical codes (ICD codes used directly, RxNormâ†’ATC)\n            sex_embed=sex_dict,                              # Converts sex categories to numerical embeddings for model input\n            age_embed=age_dict,                              # Bins and encodes patient ages into discrete categories\n            state_embed=state_dict,                          # Converts state information into numerical embeddings\n            mask_drugs=params['mask_drugs'],                                 # Enables drug code masking for MLM pretraining task\n            delete_temporary_variables=params['delete_temporary_variables'],                 # Cleans up memory by removing intermediate processing variables\n            split_sequence=params['split_sequence'],                             # Splits long patient sequences into manageable chunks if needed\n            drop_duplicates=params['drop_duplicates'],                            # Removes redundant codes to prevent sequence bias\n            converted_codes=params['converted_codes'],                           # Indicates if codes are in raw form (False) or already converted to standard format\n            convert_rxcui_to_atc=params['convert_rxcui_to_atc'],                       # Enables automatic conversion of RxNorm to ATC for drug standardization\n            keep_min_unmasked=params['min_unmasked'],                             # Ensures at least one token remains unmasked for context in MLM\n            max_masked_tokens=params['max_masked'],                            # Limits masked tokens to prevent too much information loss\n            masked_lm_prob=params['masked_lm_prob'],                             # Probability of masking each token, following BERT's approach\n            truncate=params['truncate'],                                # Specifies to remove older events when truncating long sequences\n            index_date=None,                                 # Optional reference date for temporal alignment of patient histories\n                                                            # Remove had_plos and endpoint_labels for pretraining - only use MLM\n            dynamic_masking=params['dynamic_masking'],                           # When False, uses static masks; True generates new masks each epoch\n            min_observations=params['min_observations'],                              # Minimum required events for valid patient sequence\n            age_usage=params['age_usage'],                                # Specifies granularity of age binning (year vs month)\n            use_cls=params['use_cls'],                                    # Adds classification token at sequence start like BERT\n            use_sep=params['use_sep'],                                    # Adds separator tokens between visits for temporal segmentation\n            valid_patient=params['valid_patient'],                              # Internal flag for tracking patient data validity\n            num_visits=None,                                 # Tracks number of unique clinical visits (set internally)\n            combined_length=None,                            # Total length of patient sequence before processing\n            unpadded_length=None                             # Original sequence length before padding to max_length\n        )\n\n        # Get encoded data for model input with evaluate=True for pretraining (enables code_labels)\n        model_input = patient.get_patient_data(\n            evaluate=True,      # Set to True for pretraining to get code_labels for MLM\n            mask_dynamically=params['dynamic_masking'],\n            code_embed=code_dict,\n            min_unmasked=params['min_unmasked'],\n            max_masked=params['max_masked'],\n            masked_lm_prob=params['masked_lm_prob'],\n            mask_drugs=params['mask_drugs']\n        )\n\n        for k, v in model_input.items():\n            print(f'  {k}: {v}')\n        if 'input_ids' in model_input:\n            print('  input_ids (codes):', code_dict.decode(model_input['input_ids']))\n        if 'sex_ids' in model_input:\n            print('  sex_ids:', sex_dict.decode(model_input['sex_ids']))\n        if 'state_ids' in model_input:\n            print('  state_ids:', state_dict.decode(model_input['state_ids']))\n        if 'age_ids' in model_input:\n            print('  age_ids:', age_dict.decode(model_input['age_ids']))\n        if 'entity_ids' in model_input:\n            print('  entity_ids:', [code_dict.ids_to_entity.get(x.item(), 'UNK') for x in model_input['entity_ids']])\n        if 'code_labels' in model_input:\n            print('  code_labels:', code_dict.decode(model_input['code_labels']))\n        df = patient.to_df(\n            code_embed=code_dict,\n            age_embed=age_dict,\n            sex_embed=sex_dict,\n            state_embed=state_dict,\n            dynamic_masking=params['dynamic_masking'],\n            mask_drugs=params['mask_drugs'],\n            min_unmasked=params['min_unmasked'],\n            max_masked=params['max_masked'],\n            masked_lm_prob=params['masked_lm_prob']\n        )\n        print(df)\n    except Exception as e:\n        print(f'Error processing patient {idx}: {e}')"
  },
  {
   "cell_type": "markdown",
   "id": "79b1defa",
   "metadata": {},
   "source": [
    "### What happens in this step?\n",
    "- Each patient's data is encoded into integer IDs using the dictionaries.\n",
    "- Masking is applied to some codes for masked language modeling (MLM) pretraining.\n",
    "- The encoded data is ready for input to a BERT-style model.\n",
    "- The decoded output and DataFrame view help with interpretability and debugging.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878905d3",
   "metadata": {},
   "source": [
    "## 7. Pretraining Focus: Masked Language Modeling Only\n",
    "\n",
    "We do NOT include endpoint labels like PLOS since it's to specific to ExMED-BERT's usecase.\n",
    "\n",
    "The key differences for pretraining setup:\n",
    "- **No endpoint labels**: We set `endpoint_labels=None` and `had_plos=None`\n",
    "- **Enable code labels**: With `evaluate=True` and no endpoint labels, `code_labels` are automatically generated for MLM\n",
    "- **Static or dynamic masking**: We can use either static masks (applied once) or dynamic masks (applied each epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e91f8b9",
   "metadata": {},
   "source": [
    "## 8. Creating Patient Objects for Pretraining\n",
    "### These are the __ACTUAL PATIENT OBJECTS USED IN PRETRAINING EXAMPLE__\n",
    "\n",
    "We now create `Patient` objects for each patient, configured specifically for pretraining with masked language modeling. Note that we exclude endpoint labels and focus purely on MLM objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7478fc5c",
   "metadata": {},
   "outputs": [],
   "source": "patient_objs = []\nfor patient_data in patients: # This would come from a huge json file up patient data in the needed format\n    patient_obj = Patient(\n        patient_id=patient_data['patient_id'],            # Unique identifier for tracking and referencing individual patients in the dataset\n        diagnoses=patient_data['diagnoses'],            # List of ICD diagnosis codes used directly without conversion\n        drugs=patient_data['drugs'],                    # List of RxNorm drug codes that will be converted to ATC for standardization\n        diagnosis_dates=patient_data['diagnosis_dates'], # Timestamps for diagnoses to maintain temporal order in sequence modeling\n        prescription_dates=patient_data['prescription_dates'], # Timestamps for prescriptions to maintain temporal order\n        birth_year=patient_data['birth_year'],           # Used to calculate patient age for age-based feature encoding\n        sex=patient_data['sex'],                         # Demographic feature encoded as MALE/FEMALE for patient characterization\n        patient_state=patient_data['patient_state'],     # Geographic feature for potential regional health pattern analysis\n        max_length=params['max_length'],                                 # Maximum sequence length - truncates or pads sequences for consistent model input\n        code_embed=code_dict,                            # Handles conversion and encoding of medical codes (ICD codes used directly, RxNormâ†’ATC)\n        sex_embed=sex_dict,                              # Converts sex categories to numerical embeddings for model input\n        age_embed=age_dict,                              # Bins and encodes patient ages into discrete categories\n        state_embed=state_dict,                          # Converts state information into numerical embeddings\n        mask_drugs=params['mask_drugs'],                                 # Enables drug code masking for MLM pretraining task\n        delete_temporary_variables=params['delete_temporary_variables'],                 # Cleans up memory by removing intermediate processing variables\n        split_sequence=params['split_sequence'],                             # Splits long patient sequences into manageable chunks if needed\n        drop_duplicates=params['drop_duplicates'],                            # Removes redundant codes to prevent sequence bias\n        converted_codes=params['converted_codes'],                           # Indicates if codes are in raw form (False) or already converted to standard format\n        convert_rxcui_to_atc=params['convert_rxcui_to_atc'],                       # Enables automatic conversion of RxNorm to ATC for drug standardization\n        keep_min_unmasked=params['min_unmasked'],                             # Ensures at least one token remains unmasked for context in MLM\n        max_masked_tokens=params['max_masked'],                            # Limits masked tokens to prevent too much information loss\n        masked_lm_prob=params['masked_lm_prob'],                             # Probability of masking each token, following BERT's approach\n        truncate=params['truncate'],                                # Specifies to remove older events when truncating long sequences\n        index_date=None,                                 # Optional reference date for temporal alignment of patient histories\n                                                        # Remove endpoint-related parameters for pure pretraining setup\n        dynamic_masking=params['dynamic_masking'],                           # When False, uses static masks; True generates new masks each epoch\n        min_observations=params['min_observations'],                              # Minimum required events for valid patient sequence\n        age_usage=params['age_usage'],                                # Specifies granularity of age binning (year vs month)\n        use_cls=params['use_cls'],                                    # Adds classification token at sequence start like BERT\n        use_sep=params['use_sep'],                                    # Adds separator tokens between visits for temporal segmentation\n        valid_patient=params['valid_patient'],                              # Internal flag for tracking patient data validity\n        num_visits=None,                                 # Tracks number of unique clinical visits (set internally)\n        combined_length=None,                            # Total length of patient sequence before processing\n        unpadded_length=None                             # Original sequence length before padding to max_length\n    )\n    patient_objs.append(patient_obj)\n    \n    # Get model input for pretraining - code_labels should be available\n    model_input = patient_obj.get_patient_data(\n        evaluate=True,        # True for pretraining to get MLM labels\n        mask_dynamically=params['dynamic_masking'],\n        code_embed=code_dict,\n        min_unmasked=params['min_unmasked'],\n        max_masked=params['max_masked'],\n        masked_lm_prob=params['masked_lm_prob'],\n        mask_drugs=params['mask_drugs']\n    )\n    print(f\"Patient {patient_data['patient_id']} model input keys: {list(model_input.keys())}\")\n    # Verify code_labels are present for MLM pretraining\n    if 'code_labels' in model_input:\n        print(f\"âœ“ Code labels available for MLM pretraining\")\n    else:\n        print(\"âœ— No code labels - check masking configuration\")"
  },
  {
   "cell_type": "markdown",
   "id": "abe32d86",
   "metadata": {},
   "source": [
    "## 9. Creating and Saving the PatientDataset\n",
    "\n",
    "The `PatientDataset` class batches multiple `Patient` objects and prepares them for model training. It handles masking, batching, and can save the dataset to disk for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8175db9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatientDataset created successfully for pretraining\n",
      "Dataset length: 28\n",
      "Sample patient data:\n",
      "Keys in sample data: ['input_ids', 'entity_ids', 'sex_ids', 'attention_mask', 'position_ids', 'state_ids', 'age_ids', 'plos_label', 'code_labels']\n",
      "âœ“ Code labels present - ready for MLM pretraining\n"
     ]
    }
   ],
   "source": [
    "# Create the PatientDataset for pretraining (remove endpoint_dict)\n",
    "patient_dataset = PatientDataset(\n",
    "    code_embed=code_dict,            # CodeDict: maps medical codes to integer IDs and handles code normalization\n",
    "    age_embed=age_dict,              # AgeDict: bins and encodes patient ages as integer IDs\n",
    "    sex_embed=sex_dict,              # SexDict: encodes sex/gender as integer IDs\n",
    "    state_embed=state_dict,          # StateDict: encodes US state information as integer IDs\n",
    "    endpoint_dict=None,              # Remove endpoint_dict for pretraining - we only need MLM\n",
    "    patient_paths=None,              # List of file paths for patient objects (None if patients are loaded in RAM)\n",
    "    max_length=params['max_length'],                   # Maximum sequence length for each patient (truncates or pads sequences)\n",
    "    do_eval=True,                    # Indicates if the dataset is for evaluation (affects patient output)\n",
    "    mask_substances=True,            # Whether to mask substances (drugs) as well as diagnoses for MLM\n",
    "    dataset_path=None,               # Path to dataset directory (used if saving/loading patients from disk)\n",
    "    patients=patient_objs,           # List of Patient objects loaded in RAM\n",
    "    dynamic_masking=params['dynamic_masking'],           # If True, masking is done dynamically each epoch; if False, static masks\n",
    "    min_unmasked=params['min_unmasked'],                  # Minimum number of unmasked tokens per patient sequence\n",
    "    max_masked=params['max_masked'],                   # Maximum number of masked tokens per patient sequence\n",
    "    masked_lm_prob=params['masked_lm_prob']              # Probability of masking each token (for MLM pretraining)\n",
    ")\n",
    "\n",
    "print(\"PatientDataset created successfully for pretraining\")\n",
    "print(f\"Dataset length: {len(patient_dataset)}\")\n",
    "print(\"Sample patient data:\")\n",
    "sample_data = patient_dataset[0]\n",
    "print(f\"Keys in sample data: {list(sample_data.keys())}\")\n",
    "if 'code_labels' in sample_data:\n",
    "    print(\"âœ“ Code labels present - ready for MLM pretraining\")\n",
    "else:\n",
    "    print(\"âœ— No code labels found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1629c6fe",
   "metadata": {},
   "source": [
    "## 10. Splitting and Saving Train/Validation Datasets for Pretraining\n",
    "\n",
    "For pretraining, we split our patient dataset into train, validation, and test sets using simple random splitting (no stratification needed since we don't have endpoint labels). This creates datasets ready for masked language modeling pretraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3a4f046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Train dataset saved to pretrain_stuff/demo_train_patient_dataset.pt (22 patients)\n",
      "âœ“ Validation dataset saved to pretrain_stuff/demo_val_patient_dataset.pt (3 patients)\n",
      "âœ“ Test dataset saved to pretrain_stuff/demo_test_patient_dataset.pt (3 patients)\n",
      "Datasets are ready for MLM pretraining!\n"
     ]
    }
   ],
   "source": [
    "# Use simple split without stratification since we don't have endpoint labels for pretraining\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get indices for splitting\n",
    "indices = list(range(len(patient_dataset)))\n",
    "\n",
    "# Split indices into train/val/test\n",
    "train_indices, temp_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create subset datasets\n",
    "train_patients = [patient_objs[i] for i in train_indices]\n",
    "val_patients = [patient_objs[i] for i in val_indices] \n",
    "test_patients = [patient_objs[i] for i in test_indices]\n",
    "\n",
    "# Create separate datasets\n",
    "train_dataset = PatientDataset(\n",
    "    code_embed=code_dict,\n",
    "    age_embed=age_dict,\n",
    "    sex_embed=sex_dict,\n",
    "    state_embed=state_dict,\n",
    "    endpoint_dict=None,  # No endpoints for pretraining\n",
    "    patients=train_patients,\n",
    "    do_eval=True,\n",
    "    max_length=params['max_length'],\n",
    "    dynamic_masking=params['dynamic_masking'],\n",
    "    min_unmasked=params['min_unmasked'],\n",
    "    max_masked=params['max_masked'],\n",
    "    masked_lm_prob=params['masked_lm_prob']\n",
    ")\n",
    "\n",
    "val_dataset = PatientDataset(\n",
    "    code_embed=code_dict,\n",
    "    age_embed=age_dict,\n",
    "    sex_embed=sex_dict,\n",
    "    state_embed=state_dict,\n",
    "    endpoint_dict=None,  # No endpoints for pretraining\n",
    "    patients=val_patients,\n",
    "    do_eval=True,\n",
    "    max_length=params['max_length'],\n",
    "    dynamic_masking=params['dynamic_masking'],\n",
    "    min_unmasked=params['min_unmasked'],\n",
    "    max_masked=params['max_masked'],\n",
    "    masked_lm_prob=params['masked_lm_prob']\n",
    ")\n",
    "\n",
    "test_dataset = PatientDataset(\n",
    "    code_embed=code_dict,\n",
    "    age_embed=age_dict,\n",
    "    sex_embed=sex_dict,\n",
    "    state_embed=state_dict,\n",
    "    endpoint_dict=None,  # No endpoints for pretraining\n",
    "    patients=test_patients,\n",
    "    do_eval=True,\n",
    "    max_length=params['max_length'],\n",
    "    dynamic_masking=params['dynamic_masking'],\n",
    "    min_unmasked=params['min_unmasked'],\n",
    "    max_masked=params['max_masked'],\n",
    "    masked_lm_prob=params['masked_lm_prob']\n",
    ")\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs('pretrain_stuff', exist_ok=True)\n",
    "\n",
    "# Save the datasets\n",
    "train_output_path = 'pretrain_stuff/demo_train_patient_dataset.pt'\n",
    "val_output_path = 'pretrain_stuff/demo_val_patient_dataset.pt'\n",
    "test_output_path = 'pretrain_stuff/demo_test_patient_dataset.pt'\n",
    "\n",
    "train_dataset.save_dataset(path=train_output_path, with_patients=True, do_copy=True)\n",
    "val_dataset.save_dataset(path=val_output_path, with_patients=True, do_copy=True)\n",
    "test_dataset.save_dataset(path=test_output_path, with_patients=True, do_copy=True)\n",
    "\n",
    "print(f'âœ“ Train dataset saved to {train_output_path} ({len(train_dataset)} patients)')\n",
    "print(f'âœ“ Validation dataset saved to {val_output_path} ({len(val_dataset)} patients)')\n",
    "print(f'âœ“ Test dataset saved to {test_output_path} ({len(test_dataset)} patients)')\n",
    "print(\"Datasets are ready for MLM pretraining!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07858765",
   "metadata": {},
   "source": [
    "---\n",
    "## Running the Pretraining Script\n",
    "\n",
    "To execute the pretraining process, please refer to the `pretrain_example.py` file. This file will start the pretraining.\n",
    "\n",
    "__Note on PLOS (Prolonged Length of Stay) Task:__ For commercial pharmaceutical applications, I thought to disable the PLOS task during pretraining. PLOS is specific to hospital acute care settings and has limited relevance for typical pharma use cases such as drug discovery, clinical trials, outpatient care management, or population health analytics. Focusing solely on Masked Language Modeling (MLM) provides better transferability to downstream pharmaceutical tasks and simplifies the training process. (We can set PLOS to false in our `config.yaml` file.)\n",
    "\n",
    "## Environment Considerations\n",
    "\n",
    "This project's development environment was set up using **Conda**. However, for deployment or running the model within a Databricks environment, it is highly recommended to create the environment using the **`poetry.lock` file**. This approach generally ensures more consistent and reproducible dependency management in production or distributed settings like Databricks.\n",
    "\n",
    "## Model Output and Logging\n",
    "\n",
    "A significant amount of model training information, including logs and run metadata, is stored in the `outputs/` and `mlruns/` directories. These directories are automatically created when the model is run for the first time.\n",
    "\n",
    "The primary output file containing the **learned model parameters (model weights)** will be found within the `outputs/` directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exmed-bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}